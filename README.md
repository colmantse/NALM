# NALM
This repository includes code for replicating the results in the paper 
"Assessing Non-autoregressive Alignment in Neural Machine Translation via Word Reordering" (2022)

Codes are based on the tensor2tensor library, for installation of the library, 
see https://github.com/tensorflow/tensor2tensor

Data are based on "word ordering without syntax" (2016) from https://github.com/allenschmaltz/word_ordering

Replicating our results can be broken down into two main steps.
1. Further preprocess the preprocessed data from Schmaltz's version of ptb data. Instructions are available in README_DATASET_CREATION.txt.

2. Train, run and evaluate NALM, NALM-pos as well as the benchmarking adapted models. Instructions are available at Usage.txt

To be released soon.
